
add_subdirectory(Utils)
add_subdirectory(gRPCModelRunner)
add_subdirectory(ONNXModelRunner)

find_package(Protobuf CONFIG REQUIRED)
# file(COPY ${CMAKE_CURRENT_SOURCE_DIR}/../Include/MLModelRunner DESTINATION ${LLVM_INCLUDE_DIR})

add_custom_target(copy-mlmodelrunner-include ALL
COMMAND ${CMAKE_COMMAND} -E copy_directory ${CMAKE_CURRENT_SOURCE_DIR}/../Include/MLModelRunner ${LLVM_INCLUDE_DIR}/MLModelRunner
DEPENDS ${CMAKE_CURRENT_SOURCE_DIR}/../Include/MLModelRunner
)

# For up-to-date instructions for installing the TFLite dependency, refer to
# the bot setup script: https://github.com/google/ml-compiler-opt/blob/main/buildbot/buildbot_init.sh
set(LLVM_HAVE_TFLITE "" CACHE BOOL "Use tflite")
if (LLVM_HAVE_TFLITE)
  find_package(tensorflow-lite REQUIRED)
endif()

# For up-to-date instructions for installing the Tensorflow dependency, refer to
# the bot setup script: https://github.com/google/ml-compiler-opt/blob/main/buildbot/buildbot_init.sh
# Specifically, assuming python3 is installed:
# python3 -m pip install --upgrade pip && python3 -m pip install --user tf_nightly==2.3.0.dev20200528
# Then set TENSORFLOW_AOT_PATH to the package install - usually it's ~/.local/lib/python3.7/site-packages/tensorflow
#
set(TENSORFLOW_AOT_PATH "" CACHE PATH "Path to TensorFlow pip install dir")

if (NOT TENSORFLOW_AOT_PATH STREQUAL "")
  set(LLVM_HAVE_TF_AOT "ON" CACHE BOOL "Tensorflow AOT available")
  set(TENSORFLOW_AOT_COMPILER
    "${TENSORFLOW_AOT_PATH}/../../../../bin/saved_model_cli"
    CACHE PATH "Path to the Tensorflow AOT compiler")
  include_directories(${TENSORFLOW_AOT_PATH}/include)
  add_subdirectory(${TENSORFLOW_AOT_PATH}/xla_aot_runtime_src
    ${CMAKE_ARCHIVE_OUTPUT_DIRECTORY}/tf_runtime)
  install(TARGETS tf_xla_runtime EXPORT LLVMExports
    ARCHIVE DESTINATION lib${LLVM_LIBDIR_SUFFIX} COMPONENT tf_xla_runtime)
  set_property(GLOBAL APPEND PROPERTY LLVM_EXPORTS tf_xla_runtime)
  
#   # Once we add more modules, we should handle this more automatically.
#   if (DEFINED LLVM_OVERRIDE_MODEL_HEADER_INLINERSIZEMODEL)
#     set(LLVM_INLINER_MODEL_PATH "none")
#   elseif(NOT DEFINED LLVM_INLINER_MODEL_PATH
#       OR "${LLVM_INLINER_MODEL_PATH}" STREQUAL ""
#       OR "${LLVM_INLINER_MODEL_PATH}" STREQUAL "autogenerate")
#     set(LLVM_INLINER_MODEL_PATH "autogenerate")
#     set(LLVM_INLINER_MODEL_AUTOGENERATED 1)
#   endif()
#   if (DEFINED LLVM_OVERRIDE_MODEL_HEADER_REGALLOCEVICTMODEL)
#     set(LLVM_RAEVICT_MODEL_PATH "none")
#   elseif(NOT DEFINED LLVM_RAEVICT_MODEL_PATH
#       OR "${LLVM_RAEVICT_MODEL_PATH}" STREQUAL ""
#       OR "${LLVM_RAEVICT_MODEL_PATH}" STREQUAL "autogenerate")
#     set(LLVM_RAEVICT_MODEL_PATH "autogenerate")
#     set(LLVM_RAEVICT_MODEL_AUTOGENERATED 1)
#   endif()
endif()


if (DEFINED LLVM_HAVE_TF_AOT OR LLVM_HAVE_TFLITE)
  message(STATUS "Enabling TF_AOT/TFLITE-based passes")

  if (LLVM_HAVE_TFLITE)
    list(APPEND MLLinkDeps
      tensorflow-lite::tensorflow-lite)
  endif()
endif()


add_llvm_component_library(LLVMMLModelRunner
PipeModelRunner.cpp

DEPENDS
copy-mlmodelrunner-include
${MLDeps}

LINK_LIBS
${MLLinkDeps}
LLVMMLModelRunnerUtils
LLVMgRPCModelRunner
# LLVMONNXModelRunner

)

# add_dependencies(LLVMMLModelRunner copy-mlmodelrunner-include)
# target_include_directories(LLVMMLModelRunner PUBLIC ${CMAKE_CURRENT_SOURCE_DIR}/../Include)
# target_link_libraries(LLVMMLModelRunner 
# PRIVATE LLVMMLModelRunnerUtils
# LLVMgRPCModelRunner
# LLVMONNXModelRunner
# # LLVMTFModelRunner
# )
set_property(TARGET LLVMMLModelRunner PROPERTY CXX_STANDARD 17)

target_link_libraries(LLVMMLModelRunner PUBLIC LLVMSerializer)
target_include_directories(LLVMMLModelRunner PUBLIC ${CMAKE_CURRENT_SOURCE_DIR}/../llvm-serializer/include)
target_include_directories(LLVMMLModelRunner PUBLIC ${CMAKE_CURRENT_SOURCE_DIR}/../Include/MLModelRunner)
